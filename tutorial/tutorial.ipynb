{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Env Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, gc\n",
    "\n",
    "import zipfile\n",
    "from os import path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "zip_file = \"sample_data/Sky303.zip\"\n",
    "data_path = \"sample_data/Sky303/\"\n",
    "\n",
    "if not path.exists(data_path):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"sample_data/\")\n",
    "\n",
    "input_indice_path = data_path + \"input_indices_{}.npy\"\n",
    "input_data_path = data_path + \"input_data_{}.npy\"\n",
    "target_path = data_path + \"output_indices_{}.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CONFIGURATIONS = 4262 # number of configuration of the problem\n",
    "IMG_SHAPE = (1355, 3384, 3)\n",
    "H, W = 128, 256 # the window size\n",
    "\n",
    "CAMERA = np.array([[2304.5479, 0,  1686.2379], # the camera matrix\n",
    "                          [0, 2305.8757, -0.0151],\n",
    "                          [0, 0, 1.]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Viz & Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1+cu92'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sky303Dataset(Dataset):\n",
    "    \"\"\"Car dataset.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Sky303Dataset,self).__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return N_CONFIGURATIONS\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        indice_np = np.load(input_indice_path.format(idx))\n",
    "        input_np = np.load(input_data_path.format(idx))\n",
    "        target_np = np.load(target_path.format(idx))\n",
    "        \n",
    "        input_bin_mask = np.zeros([H, W, 1], dtype='float16')\n",
    "        input_bin_mask[indice_np[:,0],indice_np[:,1],:] = 1.\n",
    "        \n",
    "        input_2Drepr = np.zeros([H, W, 3], dtype='float16')\n",
    "        input_2Drepr[indice_np[:,0],indice_np[:,1],:] = input_np\n",
    "        \n",
    "        target_2Drepr = np.zeros([H, W, 1], dtype='float16')\n",
    "        target_2Drepr[target_np[:,0],target_np[:,1],:] = 1.\n",
    "        \n",
    "        input_bin_mask = np.rollaxis(input_bin_mask, 2, 0)\n",
    "        input_bin_mask = torch.from_numpy(input_bin_mask).float()\n",
    "        \n",
    "        input_2Drepr = np.rollaxis(input_2Drepr, 2, 0)\n",
    "        input_2Drepr = torch.from_numpy(input_2Drepr).float()\n",
    "        \n",
    "        target_2Drepr = np.rollaxis(target_2Drepr, 2, 0)\n",
    "        target_2Drepr = torch.from_numpy(target_2Drepr).float()\n",
    "        \n",
    "        return [input_bin_mask, input_2Drepr, target_2Drepr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = Sky303Dataset()\n",
    "input_bin_mask, input_2Drepr, target_2Drepr = dataset[0]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow((input_bin_mask.permute(1,2,0).numpy()[:,:,-1]).squeeze())\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(input_2Drepr.permute(1,2,0).numpy()[:,:,-1]/350.)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow((target_2Drepr.permute(1,2,0).numpy()[:,:,-1]).squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# importing the importlib.util module\n",
    "import importlib.util\n",
    "\n",
    "# Define the module path\n",
    "module_path = \"../smap/smap.py\"\n",
    "\n",
    "# Load the module using importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"smap\", module_path)\n",
    "smap_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"smap\"] = smap_module\n",
    "spec.loader.exec_module(smap_module)\n",
    "\n",
    "# Gets the GPU if there is one, otherwise the cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, camera_matrix, n=0):\n",
    "        super(Model,self).__init__()\n",
    "        self.n = n\n",
    "        self.camera_matrix = nn.Parameter(torch.from_numpy(camera_matrix), requires_grad=False)\n",
    "        self.camera_matrix_inv = nn.Parameter(torch.from_numpy(np.linalg.inv(camera_matrix)), requires_grad=False)\n",
    "        \n",
    "        self.phi = nn.Parameter(torch.from_numpy(np.array([.0])).float().reshape(1,1), requires_grad=True)\n",
    "        self.gamma = nn.Parameter(torch.from_numpy(np.array([.0])).float().reshape(1,1), requires_grad=True)\n",
    "        self.rho = nn.Parameter(torch.from_numpy(np.array([.0])).float().reshape(1,1), requires_grad=True)\n",
    "        self.theta = nn.Parameter(torch.from_numpy(np.array([0.,-0.,0.])).float().reshape(1,3,1,1), requires_grad=True)\n",
    "        self.smap_layer = smap_module.SMap(n, camera_matrix)\n",
    "        \n",
    "        self.I00 = nn.Parameter(torch.from_numpy(np.array([[1.,.0,.0],[.0,0.,.0],[.0,.0,0.]])).float().reshape(3,3), requires_grad=False)\n",
    "        self.I01 = nn.Parameter(torch.from_numpy(np.array([[0.,1.,.0],[.0,0.,.0],[.0,.0,0.]])).float().reshape(3,3), requires_grad=False)\n",
    "        self.I10 = nn.Parameter(torch.from_numpy(np.array([[0.,.0,.0],[1.,0.,.0],[.0,.0,0.]])).float().reshape(3,3), requires_grad=False)\n",
    "        self.I11 = nn.Parameter(torch.from_numpy(np.array([[0.,.0,.0],[.0,1.,.0],[.0,.0,0.]])).float().reshape(3,3), requires_grad=False)\n",
    "        self.I22 = nn.Parameter(torch.from_numpy(np.array([[0.,.0,.0],[.0,0.,.0],[.0,.0,1.]])).float().reshape(3,3), requires_grad=False)\n",
    "        \n",
    "    def to_3d(self, z, height, width, panels, original_size):\n",
    "        y_im, x_im = panels\n",
    "        y_im, x_im = torch.from_numpy(y_im).reshape(height, width), torch.from_numpy(x_im).reshape(height, width)\n",
    "        y_im = y_im * IMG_SHAPE[0] / original_size[0]\n",
    "        x_im = x_im * IMG_SHAPE[1] / original_size[1]\n",
    "        y_im, x_im = y_im.to(device), x_im.to(device)\n",
    "        \n",
    "        imp_co = torch.cat([torch.einsum('hw,bczhw->bczhw', x_im.float(), torch.ones_like(z.unsqueeze(2)).float()), torch.einsum('hw,bczhw->bczhw', y_im.float(), torch.ones_like(z.unsqueeze(2)).float()), torch.ones_like(z.unsqueeze(2))], 2)\n",
    "        imp_co = imp_co.reshape(z.size(0),z.size(1),3,height,width)\n",
    "        imp_co = torch.einsum('bchw,bczhw->bczhw', z.float(), imp_co.float()).reshape(z.size(0),z.size(1),3,-1)\n",
    "        regr_co = torch.einsum('xz,yz->xy', imp_co.reshape(z.size(0),z.size(1),3,-1).permute(0,1,3,2).reshape(-1,3).float(), self.camera_matrix_inv.float())\n",
    "        regr_co = regr_co.reshape(z.size(0),z.size(1),-1,3).permute(0,1,3,2).reshape(z.size(0),z.size(1),3,height*width)\n",
    "        return regr_co\n",
    "        \n",
    "    def forward(self, r_x, r_mask, target_2Dr=None, zoom=0):\n",
    "        mask = r_mask\n",
    "        \n",
    "        x = r_x[:,-1:,:,:]\n",
    "        height, width = x.size(-2), x.size(-1)\n",
    "        panels = list(np.where(np.ones([height, width])))\n",
    "        panels[0] = panels[0] + .5\n",
    "        panels[1] = panels[1] + .5\n",
    "        \n",
    "        x = self.to_3d(x[:,-1:,:,:].reshape(-1,1,height,width), height, width, panels, (height, width)).reshape(-1,3,height,width)\n",
    "        \n",
    "        phi = torch.tanh(3e-2*self.phi)*np.pi\n",
    "        gamma = torch.tanh(3e-2*self.gamma)*np.pi\n",
    "        rho = torch.tanh(3e-2*self.rho)*np.pi\n",
    "        r = torch.cos(phi)*self.I00-torch.sin(phi)*self.I01+torch.sin(phi)*self.I10+torch.cos(phi)*self.I11+self.I22\n",
    "        y = torch.cos(gamma)*self.I00-torch.sin(gamma)*self.I01+torch.sin(gamma)*self.I10+torch.cos(gamma)*self.I11+self.I22\n",
    "        p = torch.cos(rho)*self.I00-torch.sin(rho)*self.I01+torch.sin(rho)*self.I10+torch.cos(rho)*self.I11+self.I22\n",
    "        \n",
    "        x_r = torch.einsum('bdef,cd->bcef',x,r.detach())+torch.einsum('bdef,cd->bcef',torch.sign(x),(r-r.detach()))\n",
    "        x_r = torch.cat([x_r[:,1:,:,:],x_r[:,:1,:,:]],dim=1)\n",
    "        x_r = torch.einsum('bdef,cd->bcef',x_r,y.detach())+torch.einsum('bdef,cd->bcef',torch.sign(x_r),(y-y.detach()))\n",
    "        x_r = torch.cat([x_r[:,1:,:,:],x_r[:,:1,:,:]],dim=1)\n",
    "        x_r = torch.einsum('bdef,cd->bcef',x_r,p.detach())+torch.einsum('bdef,cd->bcef',torch.sign(x_r),(p-p.detach()))\n",
    "        x_r = torch.cat([x_r[:,1:,:,:],x_r[:,:1,:,:]],dim=1)\n",
    "        \n",
    "        x_t = x_r.detach()+self.theta\n",
    "        x_t = torch.where((x[:,-1:,:,:])>0.,x_t,x_t.detach())\n",
    "        x_t = torch.where((mask>.5),x_t,torch.zeros_like(x_t))\n",
    "        k_t = torch.where((x_t[:,-1:,:,:])>0.,5./(torch.abs(x_t[:,-1:,:,:])+1e-7),torch.ones_like(x_t[:,-1:,:,:]))\n",
    "        \n",
    "        x_r = x_r+(mask>.5).float()*self.theta.detach()\n",
    "\n",
    "        weights = self.smap_layer(torch.cat([k_t*x_t+(x_r-x_r.detach()), mask], dim=1), target_2Dr, zoom)\n",
    "\n",
    "        return phi, gamma, rho, mask, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(camera_matrix, n):\n",
    "    return Model(camera_matrix, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, valid_idx= train_test_split(\n",
    "    np.random.choice(np.arange(N_CONFIGURATIONS), size=512, replace=False), test_size=0.25, random_state=0, shuffle=True)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SequentialSampler(valid_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_error(pred, target):\n",
    "    shapes = target.size()\n",
    "    m_batch_size, height, width = shapes[0], shapes[-2], shapes[-1]\n",
    "    \n",
    "    pred = pred.reshape(m_batch_size, -1, height*width)\n",
    "    pred_m = (torch.max(pred.reshape(m_batch_size, -1, height*width),dim=1,keepdim=True).values>.5).float()\n",
    "    target = target.reshape(m_batch_size, 1, -1)\n",
    "    target_m = target.reshape(m_batch_size, 1, -1)\n",
    "    \n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(pred_m.float().reshape(m_batch_size, height,width)[0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(target_m.reshape(m_batch_size, height,width)[0,:,:].detach().cpu().numpy())\n",
    "    plt.show()\n",
    "    \n",
    "    loss = torch.abs(pred-target)\n",
    "    loss_m = torch.abs(pred_m-target_m)*pred_m\n",
    "    \n",
    "    loss = loss.reshape(m_batch_size, -1).sum(dim=1)\n",
    "    loss_m = loss_m.reshape(m_batch_size, -1).sum(dim=1)\n",
    "    \n",
    "    loss = torch.mean(loss_m).detach()+(loss-loss.detach()).sum()\n",
    "    return loss\n",
    "\n",
    "def train_loop_fn(loader, zoom, epoch, history=None):\n",
    "    model.train()\n",
    "    for batch_idx, (r_mask_batch, input_2Dr_batch, target_2Dr_batch) in enumerate(tqdm(loader)):\n",
    "        m_batchsize, height, width = r_mask_batch.size(0), r_mask_batch.size(-2), r_mask_batch.size(-1)\n",
    "        if m_batchsize != batch_size:\n",
    "            break\n",
    "        else:\n",
    "            r_mask_batch, input_2Dr_batch, target_2Dr_batch = r_mask_batch.to(device), input_2Dr_batch.to(device), target_2Dr_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        r, p, y, r_mask, weights = model(input_2Dr_batch, r_mask_batch, target_2Dr_batch, zoom)\n",
    "        \n",
    "        target_2Dr = target_2Dr_batch.reshape(m_batchsize,1,H//(2**zoom),(2**zoom),W//(2**zoom),(2**zoom)).permute(0,3,5,1,2,4).reshape(m_batchsize,(2**(zoom+zoom)),1,H//(2**zoom),W//(2**zoom))\n",
    "        target_2Dr, _ = torch.max(target_2Dr,dim=1,keepdim=False)\n",
    "        \n",
    "        r_mask = r_mask_batch.reshape(m_batchsize,1,H//(2**zoom),(2**zoom),W//(2**zoom),(2**zoom)).permute(0,3,5,1,2,4).reshape(m_batchsize,(2**(zoom+zoom)),1,H//(2**zoom),W//(2**zoom))\n",
    "        r_mask, _ = torch.max(r_mask,dim=1,keepdim=False)\n",
    "\n",
    "\n",
    "        loss = l1_error(weights, target_2Dr)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        p = torch.tanh(3e-2*model.phi)*np.pi\n",
    "        y = torch.tanh(3e-2*model.gamma)*np.pi\n",
    "        r = torch.tanh(3e-2*model.rho)*np.pi\n",
    "        print('theta_x: %.4f' % ((model.theta[0,0,0,0]).detach().cpu().numpy()))\n",
    "        print('theta_y: %.4f' % ((model.theta[0,1,0,0]).detach().cpu().numpy()))\n",
    "        print('theta_z: %.4f' % ((model.theta[0,2,0,0]).detach().cpu().numpy()))\n",
    "        print('phi: %.4f' % ((r[0,0]).detach().cpu().numpy()))\n",
    "        print('gamma: %.4f' % ((p[0,0]).detach().cpu().numpy()))\n",
    "        print('rho: %.4f' % ((y[0,0]).detach().cpu().numpy()))\n",
    "\n",
    "        loss_np = loss.detach().cpu().numpy()\n",
    "\n",
    "        history.loc[(zoom, epoch, batch_idx), 'theta_x'] = (model.theta[0,0,0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'theta_y'] = (model.theta[0,1,0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'theta_z'] = (model.theta[0,2,0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'phi'] = (r[0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'gamma'] = (p[0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'rho'] = (y[0,0]).detach().cpu().numpy()\n",
    "        history.loc[(zoom, epoch, batch_idx), 'loss'] = loss_np\n",
    "        \n",
    "    print('Train Epoch: ({}, {}) \\tLR: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "            zoom, epoch,\n",
    "            optimizer.state_dict()['param_groups'][0]['lr'],\n",
    "            history['loss'].iloc[(-len(train_loader)+1):].mean()))\n",
    "    \n",
    "def evaluate_model(loader, key, history=None):\n",
    "    model.eval()\n",
    "    loss_np = 0.\n",
    "    count = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (r_mask_batch, input_2Dr_batch, target_2Dr_batch) in enumerate(tqdm(loader)):\n",
    "            m_batchsize = r_mask_batch.size(0)\n",
    "            if m_batchsize != batch_size:\n",
    "                break\n",
    "            r_mask_batch, input_2Dr_batch, target_2Dr_batch = r_mask_batch.to(device), input_2Dr_batch.to(device), target_2Dr_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            r, p, y, r_mask, weights = model(input_2Dr_batch, r_mask_batch, target_2Dr_batch)\n",
    "            \n",
    "            l1 = l1_error(weights, target_2Dr_batch)\n",
    "            loss_np += l1.detach().cpu().numpy()\n",
    "            count = count+1.\n",
    "    loss_np /= count\n",
    "    history.loc[key, 'theta_x'] = (model.theta[0,0,0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'theta_y'] = (model.theta[0,1,0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'theta_z'] = (model.theta[0,2,0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'phi'] = (r[0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'gamma'] = (p[0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'rho'] = (y[0,0]).detach().cpu().numpy()\n",
    "    history.loc[key, 'dev_loss'] = loss_np\n",
    "    print(\"n_epochs: {} - lr: {}\".format(*key))\n",
    "    print('theta_x: {:.4f}'.format((model.theta[0,0,0,0]).detach().cpu().numpy()))\n",
    "    print('theta_y: {:.4f}'.format((model.theta[0,1,0,0]).detach().cpu().numpy()))\n",
    "    print('theta_z: {:.4f}'.format((model.theta[0,2,0,0]).detach().cpu().numpy()))\n",
    "    print('phi: {:.4f}'.format((r[0,0]).detach().cpu().numpy()))\n",
    "    print('gamma: {:.4f}'.format((p[0,0]).detach().cpu().numpy()))\n",
    "    print('rho: {:.4f}'.format((y[0,0]).detach().cpu().numpy()))\n",
    "    print('Dev loss: {:.4f}'.format(loss_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/24 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'batch_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e9862bae2b0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                 \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[0mtrain_loop_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m                 \u001b[1;31m# scheduler.step()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-b47cfdbe7dbc>\u001b[0m in \u001b[0;36mtrain_loop_fn\u001b[1;34m(loader, zoom, epoch, history)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_2Dr_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_mask_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_2Dr_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mtarget_2Dr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_2Dr_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_batchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_batchsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-6a106e654cde>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, r_x, r_mask, target_2Dr, zoom)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_r\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msmap_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk_t\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_r\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_2Dr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\data_science\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\SMap\\smap\\smap.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, target_2Dr, zoom)\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget_2Dr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mtarget_2Dr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_2Dr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight_zoom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC_zoom_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth_zoom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC_zoom_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mC_zoom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight_zoom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth_zoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mzoom\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_2Dr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight_zoom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth_zoom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'batch_size' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "%time\n",
    "\n",
    "\n",
    "n_epochs_list = [4]\n",
    "lr_list = [1e-5]\n",
    "batch_size = 16\n",
    "n = 4\n",
    "optimizer = None\n",
    "model = None\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0, sampler=train_sampler)\n",
    "dev_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=0, sampler=valid_sampler)\n",
    "\n",
    "fileName = None\n",
    "dev_history = pd.DataFrame(index=pd.MultiIndex.from_tuples((), names=['epoch', 'lr']), columns=['theta_x', 'theta_y', 'theta_z', 'dev_loss'])\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "for i_epoch in range(len(n_epochs_list)):\n",
    "    for i_lr in range(len(lr_list)):\n",
    "        n_epochs = n_epochs_list[i_epoch]\n",
    "        lr = lr_list[i_lr]\n",
    "        train_history = pd.DataFrame(index=pd.MultiIndex.from_tuples((), names=['zoom', 'epoch', 'batch_id']), columns=['theta_x', 'theta_y', 'theta_z', 'loss'])\n",
    "\n",
    "        model = create_model(CAMERA, n)\n",
    "        if fileName is not None:\n",
    "            state_dict = torch.load(fileName, map_location='cpu')\n",
    "            model.load_state_dict(state_dict, strict=False)\n",
    "            del state_dict\n",
    "            print(\"Loaded!!\")\n",
    "        model = model.to(device)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        gc.collect()\n",
    "        optimizer = optim.SGD(list(model.parameters()), lr=lr)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=n_epochs, gamma=.5)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        for i in range(n+1):\n",
    "            for epoch in range(n_epochs):\n",
    "                zoom = n-i\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "\n",
    "                loader = train_loader\n",
    "                train_loop_fn(loader, zoom, epoch, train_history)\n",
    "                \n",
    "                # scheduler.step()\n",
    "\n",
    "        loader = dev_loader\n",
    "        start = time.time()*1000.0\n",
    "        evaluate_model(loader, (n_epochs, lr), dev_history)\n",
    "        t_interval = time.time()*1000.0 - start\n",
    "        print(\"Speed: {} ms/sample\".format(t_interval/(len(dev_loader)*batch_size)))\n",
    "\n",
    "        gc.collect()\n",
    "        optimizer = None\n",
    "        gc.collect()\n",
    "\n",
    "        train_history.to_csv('train_history_{}_{}.csv'.format(i_epoch, i_lr))\n",
    "        torch.save(model.state_dict(), \"./model_{}_{}.pth\".format(i_epoch, i_lr))\n",
    "dev_history.to_csv('dev_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(len(n_epochs_list)):\n",
    "    for i_lr in range(len(lr_list)):\n",
    "        train_history = pd.read_csv('train_history_{}_{}.csv'.format(i_epoch, i_lr))\n",
    "        train_history[['loss']].plot();\n",
    "        train_history[['theta_x', 'theta_y', 'theta_z']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(len(n_epochs_list)):\n",
    "    for i_lr in range(len(lr_list)):\n",
    "        train_history = pd.read_csv('train_history_{}_{}.csv'.format(i_epoch, i_lr))\n",
    "        train_history[['loss']].plot();\n",
    "        train_history[['phi', 'gamma', 'rho']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(len(n_epochs_list)):\n",
    "    for i_lr in range(len(lr_list)):\n",
    "        train_history = pd.read_csv('train_history_{}_{}.csv'.format(i_epoch, i_lr))\n",
    "        ax = train_history[['theta_x', 'theta_y', 'theta_z']].plot()\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig('./position.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_epoch in range(len(n_epochs_list)):\n",
    "    for i_lr in range(len(lr_list)):\n",
    "        train_history = pd.read_csv('train_history_{}_{}.csv'.format(i_epoch, i_lr))\n",
    "        ax = train_history[['phi', 'gamma', 'rho']].plot()\n",
    "        fig = ax.get_figure()\n",
    "        fig.savefig('./orientation.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
